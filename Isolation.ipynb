{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Finish all TODO items in this file to complete the isolation project, then\n",
    "test your agent's strength against a set of known agents using tournament.py\n",
    "and include the results in your report.\n",
    "\"\"\"\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SearchTimeout(Exception):\n",
    "    \"\"\"Subclass base exception for code clarity. \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_score(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    This should be the best heuristic function for your project submission.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    if game.is_loser(player):\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    if game.is_winner(player):\n",
    "        return float(\"inf\")\n",
    "\n",
    "    return float(len(game.get_legal_moves(player)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_score_2(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    if game.is_loser(player):\n",
    "        return float(\"-inf\")\n",
    "    if game.is_winner(player):\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    own_moves = len(game.get_legal_moves(player))\n",
    "    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(own_moves - opp_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_score_3(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    if game.is_loser(player):\n",
    "        return float(\"-inf\")\n",
    "    if game.is_winner(player):\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    # Ideas: Adaptive agresiveness for weighted evaluation function    \n",
    "    blank_spaces_propotion = len(game.get_blank_spaces()) / len(game._board_state)\n",
    "    aggresiveness = 8 / blank_spaces_propotion\n",
    "    own_moves = len(game.get_legal_moves(player))\n",
    "    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(own_moves - aggresiveness * opp_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IsolationPlayer:\n",
    "    \"\"\"Base class for minimax and alphabeta agents -- this class is never\n",
    "    constructed or tested directly.\n",
    "\n",
    "    ********************  DO NOT MODIFY THIS CLASS  ********************\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_depth : int (optional)\n",
    "        A strictly positive integer (i.e., 1, 2, 3,...) for the number of\n",
    "        layers in the game tree to explore for fixed-depth search. (i.e., a\n",
    "        depth of one (1) would only explore the immediate sucessors of the\n",
    "        current state.)\n",
    "\n",
    "    score_fn : callable (optional)\n",
    "        A function to use for heuristic evaluation of game states.\n",
    "\n",
    "    timeout : float (optional)\n",
    "        Time remaining (in milliseconds) when search is aborted. Should be a\n",
    "        positive value large enough to allow the function to return before the\n",
    "        timer expires.\n",
    "    \"\"\"\n",
    "    def __init__(self, search_depth=3, score_fn=custom_score, timeout=10.):\n",
    "        self.search_depth = search_depth\n",
    "        self.score = score_fn\n",
    "        self.time_left = None\n",
    "        self.TIMER_THRESHOLD = timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MinimaxPlayer(IsolationPlayer):\n",
    "    \"\"\"Game-playing agent that chooses a move using depth-limited minimax\n",
    "    search. You must finish and test this player to make sure it properly uses\n",
    "    minimax to return a good move before the search time limit expires.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_move(self, game, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "\n",
    "        **************  YOU DO NOT NEED TO MODIFY THIS FUNCTION  *************\n",
    "\n",
    "        For fixed-depth search, this function simply wraps the call to the\n",
    "        minimax method, but this method provides a common interface for all\n",
    "        Isolation agents, and you will replace it in the AlphaBetaPlayer with\n",
    "        iterative deepening search.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "        self.time_left = time_left\n",
    "\n",
    "        # Initialize the best move so that this function returns something\n",
    "        # in case the search fails due to timeout\n",
    "        best_move = (-1, -1)\n",
    "        \n",
    "        try:\n",
    "            # The try/except block will automatically catch the exception\n",
    "            # raised when the timer is about to expire.\n",
    "            return self.minimax(game, self.search_depth)            \n",
    "\n",
    "        except SearchTimeout:\n",
    "            legal_moves = game.get_legal_moves()\n",
    "            if not legal_moves:\n",
    "                return best_move\n",
    "            return legal_moves[0]\n",
    "            pass  # Handle any actions required after timeout as needed\n",
    "\n",
    "        # Return the best move from the last completed search iteration\n",
    "        \n",
    "        return best_move\n",
    "\n",
    "    def minimax(self, game, depth):\n",
    "        \"\"\"Implement depth-limited minimax search algorithm as described in\n",
    "        the lectures.\n",
    "\n",
    "        This should be a modified version of MINIMAX-DECISION in the AIMA text.\n",
    "        https://github.com/aimacode/aima-pseudocode/blob/master/md/Minimax-Decision.md\n",
    "\n",
    "        **********************************************************************\n",
    "            You MAY add additional methods to this class, or define helper\n",
    "                 functions to implement the required functionality.\n",
    "        **********************************************************************\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : isolation.Board\n",
    "            An instance of the Isolation game `Board` class representing the\n",
    "            current game state\n",
    "\n",
    "        depth : int\n",
    "            Depth is an integer representing the maximum number of plies to\n",
    "            search in the game tree before aborting\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            The board coordinates of the best move found in the current search;\n",
    "            (-1, -1) if there are no legal moves\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "            (1) You MUST use the `self.score()` method for board evaluation\n",
    "                to pass the project tests; you cannot call any other evaluation\n",
    "                function directly.\n",
    "\n",
    "            (2) If you use any helper functions (e.g., as shown in the AIMA\n",
    "                pseudocode) then you must copy the timer check into the top of\n",
    "                each helper function or else your agent will timeout during\n",
    "                testing.\n",
    "        \"\"\"\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "\n",
    "        legal_moves = game.get_legal_moves()\n",
    "        if not legal_moves:\n",
    "            return (-1, -1)\n",
    "        \n",
    "        assert(depth > 0)\n",
    "        \n",
    "        return max(legal_moves, \n",
    "                   key=lambda m: self.min_value(game.forecast_move(m), depth - 1))\n",
    "    \n",
    "    def min_value(self, game, depth):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "        \n",
    "        # available moves for opponent player \n",
    "        legal_moves = game.get_legal_moves()\n",
    "        # our player wins\n",
    "        if not legal_moves:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        # return score from the point of view of our player\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "        \n",
    "        return min((self.max_value(game.forecast_move(m), depth-1) \\\n",
    "                    for m in legal_moves))\n",
    "    \n",
    "    def max_value(self, game, depth):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "        \n",
    "        # available moves for our player\n",
    "        legal_moves = game.get_legal_moves()\n",
    "        # our player loses\n",
    "        if not legal_moves:\n",
    "            return float(\"-inf\")\n",
    "            \n",
    "        # return score from the point of view of the our player\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "        \n",
    "        return max((self.min_value(game.forecast_move(m), depth-1) \\\n",
    "                    for m in legal_moves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlphaBetaPlayer(IsolationPlayer):\n",
    "    \"\"\"Game-playing agent that chooses a move using iterative deepening minimax\n",
    "    search with alpha-beta pruning. You must finish and test this player to\n",
    "    make sure it returns a good move before the search time limit expires.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_move(self, game, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "\n",
    "        Modify the get_move() method from the MinimaxPlayer class to implement\n",
    "        iterative deepening search instead of fixed-depth search.\n",
    "\n",
    "        **********************************************************************\n",
    "        NOTE: If time_left() < 0 when this function returns, the agent will\n",
    "              forfeit the game due to timeout. You must return _before_ the\n",
    "              timer reaches 0.\n",
    "        **********************************************************************\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "        self.time_left = time_left\n",
    "\n",
    "        # Initialize the best move so that this function returns something\n",
    "        # in case the search fails due to timeout\n",
    "        best_move = (-1, -1)\n",
    "        \n",
    "        try:\n",
    "            # The try/except block will automatically catch the exception\n",
    "            # raised when the timer is about to expire.\n",
    "            self.search_depth = 1\n",
    "            while True:\n",
    "                best_move = self.alphabeta(game, self.search_depth)\n",
    "                self.search_depth += 1\n",
    "\n",
    "        except SearchTimeout:\n",
    "            return best_move\n",
    "#             legal_moves = game.get_legal_moves()\n",
    "#             if not legal_moves:\n",
    "#                 return best_move\n",
    "#             return legal_moves[0]\n",
    "            pass  # Handle any actions required after timeout as needed\n",
    "\n",
    "        # Return the best move from the last completed search iteration\n",
    "        \n",
    "        return best_move\n",
    "\n",
    "    def alphabeta(self, game, depth, alpha=float(\"-inf\"), beta=float(\"inf\")):\n",
    "        \"\"\"Implement depth-limited minimax search with alpha-beta pruning as\n",
    "        described in the lectures.\n",
    "\n",
    "        This should be a modified version of ALPHA-BETA-SEARCH in the AIMA text\n",
    "        https://github.com/aimacode/aima-pseudocode/blob/master/md/Alpha-Beta-Search.md\n",
    "\n",
    "        **********************************************************************\n",
    "            You MAY add additional methods to this class, or define helper\n",
    "                 functions to implement the required functionality.\n",
    "        **********************************************************************\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : isolation.Board\n",
    "            An instance of the Isolation game `Board` class representing the\n",
    "            current game state\n",
    "\n",
    "        depth : int\n",
    "            Depth is an integer representing the maximum number of plies to\n",
    "            search in the game tree before aborting\n",
    "\n",
    "        alpha : float\n",
    "            Alpha limits the lower bound of search on minimizing layers\n",
    "\n",
    "        beta : float\n",
    "            Beta limits the upper bound of search on maximizing layers\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            The board coordinates of the best move found in the current search;\n",
    "            (-1, -1) if there are no legal moves\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "            (1) You MUST use the `self.score()` method for board evaluation\n",
    "                to pass the project tests; you cannot call any other evaluation\n",
    "                function directly.\n",
    "\n",
    "            (2) If you use any helper functions (e.g., as shown in the AIMA\n",
    "                pseudocode) then you must copy the timer check into the top of\n",
    "                each helper function or else your agent will timeout during\n",
    "                testing.\n",
    "        \"\"\"\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "\n",
    "        legal_moves = game.get_legal_moves()\n",
    "        if not legal_moves:\n",
    "            return (-1, -1)\n",
    "        \n",
    "        assert(depth > 0)\n",
    "        \n",
    "        m = self.max_value(game, depth, float(\"-inf\"), float(\"inf\"), get_move=True)\n",
    "        return m\n",
    "\n",
    "    def min_value(self, game, depth, alpha, beta):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "        \n",
    "        # available moves for opponent player \n",
    "        legal_moves = game.get_legal_moves()\n",
    "        # our player wins\n",
    "        if not legal_moves:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        # return score from the point of view of our player\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "        \n",
    "        v = float(\"inf\")\n",
    "        for m in legal_moves:\n",
    "            v = min(v, self.max_value(game.forecast_move(m), depth - 1, alpha, beta))\n",
    "            if v <= alpha:\n",
    "                return v\n",
    "            beta = min(beta, v)\n",
    "        \n",
    "        return v\n",
    "    \n",
    "    def max_value(self, game, depth, alpha, beta, get_move=False):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "        \n",
    "        # available moves for our player\n",
    "        legal_moves = game.get_legal_moves()\n",
    "        # our player loses\n",
    "        if not legal_moves:\n",
    "            return (-1, -1) if get_move else float(\"-inf\")\n",
    "        \n",
    "        # return score from the point of view of the our player\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "        \n",
    "        max_v = float(\"-inf\")\n",
    "        best_move = (-1, -1)\n",
    "        for m in legal_moves:\n",
    "            v = self.min_value(game.forecast_move(m), depth - 1, alpha, beta)\n",
    "            if v > max_v:\n",
    "                best_move = m\n",
    "                max_v = v\n",
    "            if max_v >= beta:\n",
    "                return best_move if get_move else max_v\n",
    "            alpha = max(alpha, max_v)\n",
    "        \n",
    "        if not get_move:\n",
    "            return max_v\n",
    "        else:\n",
    "            return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_moves_info(player, game, depth):\n",
    "    values = {}\n",
    "    legal_moves = game.get_legal_moves()\n",
    "    for m in legal_moves:\n",
    "        values[m] = player.min_value(game.forecast_move(m), depth - 1)\n",
    "    for move, value in values.items():\n",
    "        print('|', ' ' * (8 - depth * 2), move, value)\n",
    "    return max(values.keys(), key=lambda move: values[move])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2   3   4   5   6   7   8\n",
      "\r",
      "0  |   |   |   |   |   |   |   |   |   | \n",
      "\r",
      "1  |   |   |   |   |   |   |   |   |   | \n",
      "\r",
      "2  |   |   |   |   |   | - |   |   |   | \n",
      "\r",
      "3  |   |   |   |   | - |   |   |   |   | \n",
      "\r",
      "4  |   |   |   |   | - | - | - | 2 |   | \n",
      "\r",
      "5  |   |   |   | - | 1 |   |   |   |   | \n",
      "\r",
      "6  |   |   |   | - |   |   | - |   |   | \n",
      "\r",
      "7  |   |   |   |   |   |   |   |   |   | \n",
      "\r",
      "8  |   |   |   |   |   |   |   |   |   | \n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# from isolation import Board\n",
    "# player1 = AlphaBetaPlayer(search_depth=1, score_fn=custom_score_3)\n",
    "# player2 = AlphaBetaPlayer(search_depth=1)\n",
    "# game = Board(player1, player2, width=9, height=9)\n",
    "# game._board_state = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 67, 41]\n",
    "# # game.apply_move((1, 2))\n",
    "# # game.apply_move((1, 0))\n",
    "# print(game.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3, 5)\n",
      "2\n",
      "(3, 5)\n",
      "3\n",
      "(3, 5)\n",
      "4\n",
      "(3, 5)\n",
      "5\n",
      "(3, 5)\n",
      "6\n",
      "(3, 5)\n",
      "7\n",
      "(3, 5)\n",
      "8\n",
      "(3, 5)\n",
      "9\n",
      "(3, 5)\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-04e0eb4b83dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mget_move\u001b[1;34m(self, game, time_left)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_depth\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36malphabeta\u001b[1;34m(self, game, depth, alpha, beta)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_move\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmax_value\u001b[1;34m(self, game, depth, alpha, beta, get_move)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_v\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmin_value\u001b[1;34m(self, game, depth, alpha, beta)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmax_value\u001b[1;34m(self, game, depth, alpha, beta, get_move)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_v\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmin_value\u001b[1;34m(self, game, depth, alpha, beta)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmax_value\u001b[1;34m(self, game, depth, alpha, beta, get_move)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_v\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmin_value\u001b[1;34m(self, game, depth, alpha, beta)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmax_value\u001b[1;34m(self, game, depth, alpha, beta, get_move)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_v\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmin_value\u001b[1;34m(self, game, depth, alpha, beta)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmax_value\u001b[1;34m(self, game, depth, alpha, beta, get_move)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_v\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmin_value\u001b[1;34m(self, game, depth, alpha, beta)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-5510283937a6>\u001b[0m in \u001b[0;36mmax_value\u001b[1;34m(self, game, depth, alpha, beta, get_move)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;31m# return score from the point of view of the our player\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mmax_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-71c6d06619a3>\u001b[0m in \u001b[0;36mcustom_score_3\u001b[1;34m(game, player)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Ideas: Adaptive agresiveness for weighted evaluation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mblank_spaces_propotion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_blank_spaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_board_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0maggresiveness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mblank_spaces_propotion\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mown_moves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AIND\\GitHub\\Isolation-adversarial-search\\isolation\\isolation.py\u001b[0m in \u001b[0;36mget_blank_spaces\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \"\"\"Return a list of the locations that are still available on the board.\n\u001b[0;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m--> 142\u001b[1;33m         return [(i, j) for j in range(self.width) for i in range(self.height)\n\u001b[0m\u001b[0;32m    143\u001b[0m                 if self._board_state[i + j * self.height] == Board.BLANK]\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AIND\\GitHub\\Isolation-adversarial-search\\isolation\\isolation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \"\"\"\n\u001b[0;32m    142\u001b[0m         return [(i, j) for j in range(self.width) for i in range(self.height)\n\u001b[1;32m--> 143\u001b[1;33m                 if self._board_state[i + j * self.height] == Board.BLANK]\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_player_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# game.apply_move(player1.get_move(game, lambda: 1000))\n",
    "# print(game.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Winner: <__main__.MinimaxPlayer object at 0x000002161B6D26A0>\n",
      "Outcome: illegal move\n",
      "     0   1   2   3   4   5   6\n",
      "\r",
      "0  |   |   |   |   |   | - |   | \n",
      "\r",
      "1  | 2 | - |   |   | - |   |   | \n",
      "\r",
      "2  |   |   | - | - | - | - |   | \n",
      "\r",
      "3  |   | - | - | - | - | - |   | \n",
      "\r",
      "4  |   | - | - | - | - | - | - | \n",
      "\r",
      "5  | - |   | - | - |   |   | - | \n",
      "\r",
      "6  |   |   | - |   | - | 1 |   | \n",
      "\r\n",
      "Move history:\n",
      "[[1, 1], [2, 4], [3, 2], [4, 5], [4, 4], [5, 3], [5, 2], [4, 1], [6, 4], [2, 2], [5, 6], [3, 4], [3, 5], [4, 2], [1, 4], [5, 0], [3, 3], [6, 2], [2, 5], [4, 3], [4, 6], [3, 1], [6, 5], [1, 0]]\n"
     ]
    }
   ],
   "source": [
    "# from isolation import Board\n",
    "# from sample_players import RandomPlayer\n",
    "# from sample_players import GreedyPlayer\n",
    "\n",
    "# # create an isolation board (by default 7x7)\n",
    "# player1 = RandomPlayer()\n",
    "# # player1 = RandomPlayer()\n",
    "# player2 = MinimaxPlayer()\n",
    "# game = Board(player1, player2)\n",
    "\n",
    "# # place player 1 on the board at row 2, column 3, then place player 2 on\n",
    "# # the board at row 0, column 5; display the resulting board state.  Note\n",
    "# # that the .apply_move() method changes the calling object in-place.\n",
    "# game.apply_move((2, 3))\n",
    "# game.apply_move((0, 5))\n",
    "# # print(game.to_string())\n",
    "\n",
    "# # players take turns moving on the board, so player1 should be next to move\n",
    "# assert(player1 == game.active_player)\n",
    "\n",
    "# # get a list of the legal moves available to the active player\n",
    "# # print(game.get_legal_moves())\n",
    "\n",
    "# # get a successor of the current state by making a copy of the board and\n",
    "# # applying a move. Notice that this does NOT change the calling object\n",
    "# # (unlike .apply_move()).\n",
    "# new_game = game.forecast_move((1, 1))\n",
    "# assert(new_game.to_string() != game.to_string())\n",
    "# # print(\"\\nOld state:\\n{}\".format(game.to_string()))\n",
    "# # print(\"\\nNew state:\\n{}\".format(new_game.to_string()))\n",
    "\n",
    "# # play the remainder of the game automatically -- outcome can be \"illegal\n",
    "# # move\", \"timeout\", or \"forfeit\"\n",
    "# winner, history, outcome = game.play()\n",
    "# print(\"\\nWinner: {}\\nOutcome: {}\".format(winner, outcome))\n",
    "# print(game.to_string())\n",
    "# print(\"Move history:\\n{!s}\".format(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
